{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-20_resnet34.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "up50HgbXHNcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WEIGHTS_COLLECTION = [\n",
        "\n",
        "    # ResNet18\n",
        "    {\n",
        "        'model': 'resnet18',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': True,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet18_imagenet_1000.h5',\n",
        "        'name': 'resnet18_imagenet_1000.h5',\n",
        "        'md5': '64da73012bb70e16c901316c201d9803',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnet18',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': False,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet18_imagenet_1000_no_top.h5',\n",
        "        'name': 'resnet18_imagenet_1000.h5',\n",
        "        'md5': '318e3ac0cd98d51e917526c9f62f0b50',\n",
        "    },\n",
        "\n",
        "    # ResNet34\n",
        "    {\n",
        "        'model': 'resnet34',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': True,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000.h5',\n",
        "        'name': 'resnet34_imagenet_1000.h5',\n",
        "        'md5': '2ac8277412f65e5d047f255bcbd10383',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnet34',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': False,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000_no_top.h5',\n",
        "        'name': 'resnet34_imagenet_1000_no_top.h5',\n",
        "        'md5': '8caaa0ad39d927cb8ba5385bf945d582',\n",
        "    },\n",
        "\n",
        "    # ResNet50\n",
        "    {\n",
        "        'model': 'resnet50',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': True,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet50_imagenet_1000.h5',\n",
        "        'name': 'resnet50_imagenet_1000.h5',\n",
        "        'md5': 'd0feba4fc650e68ac8c19166ee1ba87f',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnet50',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': False,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet50_imagenet_1000_no_top.h5',\n",
        "        'name': 'resnet50_imagenet_1000_no_top.h5',\n",
        "        'md5': 'db3b217156506944570ac220086f09b6',\n",
        "    },\n",
        "\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx0CNrmxHOFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from . import get_submodules_from_kwargs\n",
        "\n",
        "__all__ = ['load_model_weights']\n",
        "\n",
        "\n",
        "def _find_weights(model_name, dataset, include_top):\n",
        "    w = list(filter(lambda x: x['model'] == model_name, WEIGHTS_COLLECTION))\n",
        "    w = list(filter(lambda x: x['dataset'] == dataset, w))\n",
        "    w = list(filter(lambda x: x['include_top'] == include_top, w))\n",
        "    return w\n",
        "\n",
        "\n",
        "def load_model_weights(model, model_name, dataset, classes, include_top, **kwargs):\n",
        "    _, _, _, keras_utils = get_submodules_from_kwargs(kwargs)\n",
        "\n",
        "    weights = _find_weights(model_name, dataset, include_top)\n",
        "\n",
        "    if weights:\n",
        "        weights = weights[0]\n",
        "\n",
        "        if include_top and weights['classes'] != classes:\n",
        "            raise ValueError('If using `weights` and `include_top`'\n",
        "                             ' as true, `classes` should be {}'.format(weights['classes']))\n",
        "\n",
        "        weights_path = get_file(\n",
        "            weights['name'],\n",
        "            weights['url'],\n",
        "            cache_subdir='models',\n",
        "            md5_hash=weights['md5']\n",
        "        )\n",
        "\n",
        "        model.load_weights(weights_path)\n",
        "\n",
        "    else:\n",
        "        raise ValueError('There is no weights for such configuration: ' +\n",
        "                         'model = {}, dataset = {}, '.format(model.name, dataset) +\n",
        "                         'classes = {}, include_top = {}.'.format(classes, include_top))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajphEaPLJ6v3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras_applications as ka\n",
        "# from .__version__ import __version__\n",
        "\n",
        "\n",
        "def get_submodules_from_kwargs(kwargs):\n",
        "    backend = kwargs.get('backend', ka._KERAS_BACKEND)\n",
        "    layers = kwargs.get('layers', ka._KERAS_LAYERS)\n",
        "    models = kwargs.get('models', ka._KERAS_MODELS)\n",
        "    utils = kwargs.get('utils', ka._KERAS_UTILS)\n",
        "    return backend, layers, models, utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpAGoLBWLm1V",
        "colab_type": "code",
        "outputId": "b7d3f416-1f4f-490e-fe9b-ac1c51c49be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import GlobalMaxPooling2D, ZeroPadding2D, Add\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.merge import add\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.utils import get_file"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcoLeEk_Gz65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        "import collections\n",
        "\n",
        "\n",
        "# from ._common_blocks import ChannelSE\n",
        "# from .. import get_submodules_from_kwargs\n",
        "# from ..weights import load_model_weights\n",
        "\n",
        "backend = None\n",
        "layers = None\n",
        "models = None\n",
        "keras_utils = None\n",
        "\n",
        "ModelParams = collections.namedtuple(\n",
        "    'ModelParams',\n",
        "    ['model_name', 'repetitions', 'residual_block', 'attention']\n",
        ")\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "#   Helpers functions\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "def handle_block_names(stage, block):\n",
        "    name_base = 'stage{}_unit{}_'.format(stage + 1, block + 1)\n",
        "    conv_name = name_base + 'conv'\n",
        "    bn_name = name_base + 'bn'\n",
        "    relu_name = name_base + 'relu'\n",
        "    sc_name = name_base + 'sc'\n",
        "    return conv_name, bn_name, relu_name, sc_name\n",
        "\n",
        "\n",
        "def get_conv_params(**params):\n",
        "    default_conv_params = {\n",
        "        'kernel_initializer': 'he_uniform',\n",
        "        'use_bias': False,\n",
        "        'padding': 'valid',\n",
        "    }\n",
        "    default_conv_params.update(params)\n",
        "    return default_conv_params\n",
        "\n",
        "\n",
        "def get_bn_params(**params):\n",
        "    axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
        "    default_bn_params = {\n",
        "        'axis': axis,\n",
        "        'momentum': 0.99,\n",
        "        'epsilon': 2e-5,\n",
        "        'center': True,\n",
        "        'scale': True,\n",
        "    }\n",
        "    default_bn_params.update(params)\n",
        "    return default_bn_params\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "#   Residual blocks\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "def residual_conv_block(filters, stage, block, strides=(1, 1), attention=None, cut='pre'):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        cut: one of 'pre', 'post'. used to decide where skip connection is taken\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "\n",
        "    def layer(input_tensor):\n",
        "\n",
        "        # get params and names of layers\n",
        "        conv_params = get_conv_params()\n",
        "        bn_params = get_bn_params()\n",
        "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
        "        x = Activation('relu', name=relu_name + '1')(x)\n",
        "\n",
        "        # defining shortcut connection\n",
        "        if cut == 'pre':\n",
        "            shortcut = input_tensor\n",
        "        elif cut == 'post':\n",
        "            shortcut = Conv2D(filters, (1, 1), name=sc_name, strides=strides, **conv_params)(x)\n",
        "        else:\n",
        "            raise ValueError('Cut type not in [\"pre\", \"post\"]')\n",
        "\n",
        "        # continue with convolution layers\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), strides=strides, name=conv_name + '1', **conv_params)(x)\n",
        "#         x = Dropout(0.2)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '2')(x)\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), name=conv_name + '2', **conv_params)(x)\n",
        "#         x = Dropout(0.2)(x)\n",
        "\n",
        "        # use attention block if defined\n",
        "        if attention is not None:\n",
        "            x = attention(x)\n",
        "\n",
        "        # add residual connection\n",
        "        x = Add()([x, shortcut])\n",
        "        return x\n",
        "\n",
        "    return layer\n",
        "\n",
        "\n",
        "def residual_bottleneck_block(filters, stage, block, strides=None, attention=None, cut='pre'):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        cut: one of 'pre', 'post'. used to decide where skip connection is taken\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "\n",
        "    def layer(input_tensor):\n",
        "\n",
        "        # get params and names of layers\n",
        "        conv_params = get_conv_params()\n",
        "        bn_params = get_bn_params()\n",
        "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
        "        x = Activation('relu', name=relu_name + '1')(x)\n",
        "\n",
        "        # defining shortcut connection\n",
        "        if cut == 'pre':\n",
        "            shortcut = input_tensor\n",
        "        elif cut == 'post':\n",
        "            shortcut = Conv2D(filters * 4, (1, 1), name=sc_name, strides=strides, **conv_params)(x)\n",
        "        else:\n",
        "            raise ValueError('Cut type not in [\"pre\", \"post\"]')\n",
        "\n",
        "        # continue with convolution layers\n",
        "        x = Conv2D(filters, (1, 1), name=conv_name + '1', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '2')(x)\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), strides=strides, name=conv_name + '2', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '3', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '3')(x)\n",
        "        x = Conv2D(filters * 4, (1, 1), name=conv_name + '3', **conv_params)(x)\n",
        "\n",
        "        # use attention block if defined\n",
        "        if attention is not None:\n",
        "            x = attention(x)\n",
        "\n",
        "        # add residual connection\n",
        "        x = Add()([x, shortcut])\n",
        "\n",
        "        return x\n",
        "\n",
        "    return layer\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "#   Residual Model Builder\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def ResNet(model_params, input_shape=None, input_tensor=None, include_top=True,\n",
        "           classes=1000, weights='imagenet', **kwargs):\n",
        "\n",
        "    global backend, layers, models, keras_utils\n",
        "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape, name='data')\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    # choose residual block type\n",
        "    ResidualBlock = model_params.residual_block\n",
        "    if model_params.attention:\n",
        "        Attention = model_params.attention(**kwargs)\n",
        "    else:\n",
        "        Attention = None\n",
        "\n",
        "    # get parameters for model layers\n",
        "    no_scale_bn_params = get_bn_params(scale=False)\n",
        "    bn_params = get_bn_params()\n",
        "    conv_params = get_conv_params()\n",
        "    init_filters = 64\n",
        "\n",
        "    # resnet bottom\n",
        "    x = BatchNormalization(name='bn_data', **no_scale_bn_params)(img_input)\n",
        "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
        "    x = Conv2D(init_filters, (7, 7), strides=(1, 1), name='conv0', **conv_params)(x)\n",
        "#     x = Dropout(0.2)(x)\n",
        "    x = BatchNormalization(name='bn0', **bn_params)(x)\n",
        "    x = Activation('relu', name='relu0')(x)\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "#     x = MaxPooling2D((3, 3), strides=(2, 2), padding='valid', name='pooling0')(x)\n",
        "\n",
        "    # resnet body\n",
        "    for stage, rep in enumerate(model_params.repetitions):\n",
        "        for block in range(rep):\n",
        "\n",
        "            filters = init_filters * (2 ** stage)\n",
        "\n",
        "            # first block of first stage without strides because we have maxpooling before\n",
        "            if block == 0 and stage == 0:\n",
        "                x = ResidualBlock(filters, stage, block, strides=(1, 1),\n",
        "                                  cut='post', attention=Attention)(x)\n",
        "\n",
        "            elif block == 0:\n",
        "                x = ResidualBlock(filters, stage, block, strides=(2, 2),\n",
        "                                  cut='post', attention=Attention)(x)\n",
        "\n",
        "            else:\n",
        "                x = ResidualBlock(filters, stage, block, strides=(1, 1),\n",
        "                                  cut='pre', attention=Attention)(x)\n",
        "\n",
        "    x = BatchNormalization(name='bn1', **bn_params)(x)\n",
        "    x = Activation('relu', name='relu1')(x)\n",
        "\n",
        "    # resnet top\n",
        "    if include_top:\n",
        "        x = GlobalAveragePooling2D(name='pool1')(x)\n",
        "        x = Dense(classes, name='fc1')(x)\n",
        "        x = Activation('softmax', name='softmax')(x)\n",
        "\n",
        "    # Ensure that the model takes into account any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "\n",
        "    # Create model.\n",
        "    model = Model(inputs, x)\n",
        "\n",
        "    if weights:\n",
        "        if type(weights) == str and os.path.exists(weights):\n",
        "            model.load_weights(weights)\n",
        "        else:\n",
        "            load_model_weights(model, model_params.model_name,\n",
        "                               weights, classes, include_top, **kwargs)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "#   Residual Models\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "MODELS_PARAMS = {\n",
        "    'resnet18': ModelParams('resnet18', (2, 2, 2, 2), residual_conv_block, None),\n",
        "    'resnet34': ModelParams('resnet34', (3, 4, 6, 3), residual_conv_block, None),\n",
        "    'resnet50': ModelParams('resnet50', (3, 4, 6, 3), residual_bottleneck_block, None),\n",
        "}\n",
        "\n",
        "\n",
        "def ResNet18(input_shape=None, input_tensor=None, weights=None, classes=1000, include_top=True, **kwargs):\n",
        "    return ResNet(\n",
        "        MODELS_PARAMS['resnet18'],\n",
        "        input_shape=input_shape,\n",
        "        input_tensor=input_tensor,\n",
        "        include_top=include_top,\n",
        "        classes=classes,\n",
        "        weights=weights,\n",
        "        **kwargs\n",
        "    )\n",
        "\n",
        "\n",
        "def ResNet34(input_shape=None, input_tensor=None, weights=None, classes=1000, include_top=True, **kwargs):\n",
        "    return ResNet(\n",
        "        MODELS_PARAMS['resnet34'],\n",
        "        input_shape=input_shape,\n",
        "        input_tensor=input_tensor,\n",
        "        include_top=include_top,\n",
        "        classes=classes,\n",
        "        weights=weights,\n",
        "        **kwargs\n",
        "    )\n",
        "\n",
        "\n",
        "def ResNet50(input_shape=None, input_tensor=None, weights=None, classes=1000, include_top=True, **kwargs):\n",
        "    return ResNet(\n",
        "        MODELS_PARAMS['resnet50'],\n",
        "        input_shape=input_shape,\n",
        "        input_tensor=input_tensor,\n",
        "        include_top=include_top,\n",
        "        classes=classes,\n",
        "        weights=weights,\n",
        "        **kwargs\n",
        "    )\n",
        "\n",
        "\n",
        "def preprocess_input(x, **kwargs):\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69aQqjcIddJP",
        "colab_type": "text"
      },
      "source": [
        "#### Changes made to the original architecture.\n",
        "Since the pretrined model is for imagenet which has input size of 224x224, and the fine tuned model is on cifar100 which has 32x32 size, incuded folloing minor changes that will reduce the effective global reciptive filed to suite 32x32:\n",
        "\n",
        "\n",
        "\n",
        "1.   The stride of first convoultion(7x7) is changed to 1 from its orignal value of 2 for the resnet model.\n",
        "2.   Max pooling layer is removed.\n",
        "\n",
        "These two steps will bring the input image size form 224 to 56 immediately before going into residual blocks. But in the case of 32x32 input image we do not need this reduction.\n",
        "\n",
        "This change will not effect the kernal weights and hence we are safe to use original weights file with out any changes.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I_CZfghgVLH",
        "colab_type": "text"
      },
      "source": [
        "In the following cell, we load imagenet pretrained model with out last fully connecred layer. This will allow us to have input size of our choice. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFhI-QbgglUq",
        "colab_type": "text"
      },
      "source": [
        "This is how we load imagenet weights to the Resnet architecture above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDjxp5C1JXCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.summary()\n",
        "model = ResNet34(input_shape=(32,32,3), weights='imagenet', classes=100, include_top=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po8msVMOgxIK",
        "colab_type": "text"
      },
      "source": [
        "**Here we add a Fully connected layer to match the cifar100 dataset, with 100 neurons in the output layer, followed by a softmax.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AMubCdoNoqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "\n",
        "x = model.output\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dropout(0.4)(x)\n",
        "predictions = keras.layers.Dense(100, activation= 'softmax')(x)\n",
        "model = Model(inputs = model.input, outputs = predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDaXhzfLN6-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0QZYPBOEfDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.layers\n",
        "# for i,l in enumerate(model.layers):\n",
        "# #   print(l.trainable,l.name)\n",
        "#   if l.name == \"stage3_unit1_bn1\":\n",
        "#     break\n",
        "#   model.layers[i].trainable = False\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFKwYTWTGS4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for l in model.layers:\n",
        "#     print(l.name,\"--\", l.trainable)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0i_o2fUN9l7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqCq5EA3OGuN",
        "colab_type": "code",
        "outputId": "25ed0d88-fc1f-4aea-ba53-6ac8d1913dea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "trainX = x_train.astype('float32')\n",
        "testX = x_test.astype('float32')\n",
        "\n",
        "trainX /= 255.\n",
        "testX /= 255.\n",
        "\n",
        "nb_classes = 100\n",
        "Y_train = to_categorical(y_train, nb_classes)\n",
        "Y_test = to_categorical(y_test, nb_classes)\n",
        "Y_train.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb1Q4Nc0N_tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7OMxFc2e3Q_",
        "colab_type": "text"
      },
      "source": [
        "#### Accuracy of 78.59% in 50 epochs on cifar100\n",
        "\n",
        "Since we removed two strided conv layer and a maxpooling layer, the resnet34 model takes much longer time to train.\n",
        "\n",
        "\n",
        "Achieved a val acc of 78.59% in 50 epochs. \n",
        "\n",
        "Achieved a aproximate val acc of 75% in 8 epochs. \n",
        "\n",
        "\n",
        "With some efficient hyperparameter turning, it should be possible to achieve higher accuracy much quickly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51jfBgVZOHG7",
        "colab_type": "code",
        "outputId": "ad07c091-61a0-4a49-cecf-6c4e872a6af9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import adam\n",
        "\n",
        "\n",
        "random_erasing = True\n",
        "pixel_level = False\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 128\n",
        "# building model with too many classes inially for simpler transfer learning afterwards\n",
        "nb_classes = 100\n",
        "nb_epoch = 100\n",
        "# lr_list = np.linspace(0, 1, num=101);print(lr_list)\n",
        "# best_acc_lr_list = []\n",
        "\n",
        "# for lri in lr_list[1:]:\n",
        "#   print(lri)\n",
        "#   model = ResNet18(input_shape=(32,32,3), weights='imagenet', classes=100, include_top=False)\n",
        "#   x = model.output\n",
        "#   x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "#   x = keras.layers.Dropout(0.4)(x)\n",
        "#   predictions = keras.layers.Dense(100, activation= 'softmax')(x)\n",
        "#   model = Model(inputs = model.input, outputs = predictions)\n",
        "  \n",
        "datagen = ImageDataGenerator(featurewise_center=False,featurewise_std_normalization=False,\n",
        "                              preprocessing_function=get_random_eraser(p=0.5,v_l=0, v_h=1, pixel_level=pixel_level))\n",
        "\n",
        "# let's train the model using SGD + momentum (how original).\n",
        "sgd = SGD(lr=0.01, decay=1e-4, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "model_info = model.fit_generator(datagen.flow(trainX, Y_train, batch_size = batch_size),\n",
        "                                   samples_per_epoch = trainX.shape[0], nb_epoch = nb_epoch,\n",
        "                                   validation_data = (testX, Y_test), verbose=1)\n",
        "score = model.evaluate(testX, Y_test, verbose=1)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=100)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 292s 748ms/step - loss: 3.1229 - acc: 0.2570 - val_loss: 2.0937 - val_acc: 0.4411\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 1.6558 - acc: 0.5406 - val_loss: 1.4208 - val_acc: 0.6005\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 1.1510 - acc: 0.6672 - val_loss: 1.1091 - val_acc: 0.6808\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.8591 - acc: 0.7455 - val_loss: 1.1699 - val_acc: 0.6730\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.6665 - acc: 0.8013 - val_loss: 1.0514 - val_acc: 0.7110\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.5323 - acc: 0.8396 - val_loss: 1.0932 - val_acc: 0.7177\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.4260 - acc: 0.8718 - val_loss: 1.1147 - val_acc: 0.7186\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.3530 - acc: 0.8943 - val_loss: 1.0057 - val_acc: 0.7435\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.3078 - acc: 0.9095 - val_loss: 1.1086 - val_acc: 0.7363\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.2586 - acc: 0.9232 - val_loss: 1.1136 - val_acc: 0.7332\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.2354 - acc: 0.9313 - val_loss: 1.0830 - val_acc: 0.7386\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.2001 - acc: 0.9414 - val_loss: 1.1278 - val_acc: 0.7368\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.1966 - acc: 0.9427 - val_loss: 1.1081 - val_acc: 0.7478\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.1693 - acc: 0.9514 - val_loss: 1.0938 - val_acc: 0.7504\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.1558 - acc: 0.9545 - val_loss: 1.0998 - val_acc: 0.7531\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.1453 - acc: 0.9592 - val_loss: 1.1656 - val_acc: 0.7427\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.1356 - acc: 0.9614 - val_loss: 1.1377 - val_acc: 0.7511\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.1267 - acc: 0.9639 - val_loss: 1.1202 - val_acc: 0.7579\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.1270 - acc: 0.9634 - val_loss: 1.0914 - val_acc: 0.7579\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.1145 - acc: 0.9681 - val_loss: 1.0875 - val_acc: 0.7599\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.1117 - acc: 0.9684 - val_loss: 1.1375 - val_acc: 0.7555\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.1029 - acc: 0.9702 - val_loss: 1.1188 - val_acc: 0.7586\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0963 - acc: 0.9733 - val_loss: 1.1689 - val_acc: 0.7553\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0941 - acc: 0.9735 - val_loss: 1.0822 - val_acc: 0.7695\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 286s 732ms/step - loss: 0.0885 - acc: 0.9745 - val_loss: 1.0987 - val_acc: 0.7655\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0848 - acc: 0.9758 - val_loss: 1.0704 - val_acc: 0.7723\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0786 - acc: 0.9779 - val_loss: 1.0908 - val_acc: 0.7650\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0828 - acc: 0.9769 - val_loss: 1.1199 - val_acc: 0.7656\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 286s 735ms/step - loss: 0.0730 - acc: 0.9796 - val_loss: 1.0866 - val_acc: 0.7707\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0762 - acc: 0.9792 - val_loss: 1.1214 - val_acc: 0.7687\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0704 - acc: 0.9804 - val_loss: 1.1100 - val_acc: 0.7684\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0697 - acc: 0.9805 - val_loss: 1.1135 - val_acc: 0.7684\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0646 - acc: 0.9820 - val_loss: 1.1126 - val_acc: 0.7669\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0648 - acc: 0.9821 - val_loss: 1.0887 - val_acc: 0.7738\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0625 - acc: 0.9830 - val_loss: 1.0811 - val_acc: 0.7739\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0618 - acc: 0.9829 - val_loss: 1.0891 - val_acc: 0.7753\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0572 - acc: 0.9840 - val_loss: 1.0802 - val_acc: 0.7772\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 285s 732ms/step - loss: 0.0580 - acc: 0.9835 - val_loss: 1.0659 - val_acc: 0.7758\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0578 - acc: 0.9834 - val_loss: 1.0847 - val_acc: 0.7762\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0536 - acc: 0.9846 - val_loss: 1.0896 - val_acc: 0.7788\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0518 - acc: 0.9846 - val_loss: 1.1002 - val_acc: 0.7743\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0537 - acc: 0.9852 - val_loss: 1.1001 - val_acc: 0.7747\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0512 - acc: 0.9850 - val_loss: 1.0927 - val_acc: 0.7733\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0499 - acc: 0.9853 - val_loss: 1.1269 - val_acc: 0.7687\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0476 - acc: 0.9865 - val_loss: 1.0683 - val_acc: 0.7800\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0459 - acc: 0.9870 - val_loss: 1.0912 - val_acc: 0.7762\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0442 - acc: 0.9875 - val_loss: 1.0929 - val_acc: 0.7779\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0426 - acc: 0.9877 - val_loss: 1.1139 - val_acc: 0.7774\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 286s 732ms/step - loss: 0.0451 - acc: 0.9868 - val_loss: 1.0909 - val_acc: 0.7767\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0430 - acc: 0.9874 - val_loss: 1.1065 - val_acc: 0.7747\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0444 - acc: 0.9876 - val_loss: 1.0861 - val_acc: 0.7817\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0392 - acc: 0.9886 - val_loss: 1.1305 - val_acc: 0.7712\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0370 - acc: 0.9893 - val_loss: 1.0840 - val_acc: 0.7774\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0363 - acc: 0.9893 - val_loss: 1.0974 - val_acc: 0.7766\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0376 - acc: 0.9891 - val_loss: 1.1091 - val_acc: 0.7774\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0370 - acc: 0.9894 - val_loss: 1.0834 - val_acc: 0.7790\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0372 - acc: 0.9894 - val_loss: 1.0905 - val_acc: 0.7793\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0372 - acc: 0.9894 - val_loss: 1.0929 - val_acc: 0.7789\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0335 - acc: 0.9907 - val_loss: 1.1082 - val_acc: 0.7797\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0347 - acc: 0.9899 - val_loss: 1.1082 - val_acc: 0.7771\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0343 - acc: 0.9901 - val_loss: 1.1073 - val_acc: 0.7763\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0324 - acc: 0.9905 - val_loss: 1.1017 - val_acc: 0.7809\n",
            "Epoch 63/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0325 - acc: 0.9903 - val_loss: 1.1100 - val_acc: 0.7770\n",
            "Epoch 64/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0332 - acc: 0.9906 - val_loss: 1.1310 - val_acc: 0.7741\n",
            "Epoch 65/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0315 - acc: 0.9906 - val_loss: 1.1185 - val_acc: 0.7774\n",
            "Epoch 66/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0331 - acc: 0.9908 - val_loss: 1.0951 - val_acc: 0.7799\n",
            "Epoch 67/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0318 - acc: 0.9909 - val_loss: 1.0986 - val_acc: 0.7831\n",
            "Epoch 68/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0277 - acc: 0.9918 - val_loss: 1.0941 - val_acc: 0.7829\n",
            "Epoch 69/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0298 - acc: 0.9919 - val_loss: 1.0989 - val_acc: 0.7837\n",
            "Epoch 70/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0274 - acc: 0.9920 - val_loss: 1.1045 - val_acc: 0.7795\n",
            "Epoch 71/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0254 - acc: 0.9930 - val_loss: 1.1130 - val_acc: 0.7788\n",
            "Epoch 72/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0296 - acc: 0.9917 - val_loss: 1.1149 - val_acc: 0.7793\n",
            "Epoch 73/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0279 - acc: 0.9922 - val_loss: 1.1111 - val_acc: 0.7775\n",
            "Epoch 74/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0268 - acc: 0.9926 - val_loss: 1.0961 - val_acc: 0.7803\n",
            "Epoch 75/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0269 - acc: 0.9925 - val_loss: 1.0946 - val_acc: 0.7806\n",
            "Epoch 76/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0233 - acc: 0.9929 - val_loss: 1.1114 - val_acc: 0.7776\n",
            "Epoch 77/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0271 - acc: 0.9920 - val_loss: 1.0992 - val_acc: 0.7774\n",
            "Epoch 78/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0261 - acc: 0.9928 - val_loss: 1.1035 - val_acc: 0.7783\n",
            "Epoch 79/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0268 - acc: 0.9926 - val_loss: 1.1211 - val_acc: 0.7766\n",
            "Epoch 80/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0256 - acc: 0.9926 - val_loss: 1.1306 - val_acc: 0.7751\n",
            "Epoch 81/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0250 - acc: 0.9927 - val_loss: 1.1357 - val_acc: 0.7767\n",
            "Epoch 82/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0244 - acc: 0.9930 - val_loss: 1.1274 - val_acc: 0.7782\n",
            "Epoch 83/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0230 - acc: 0.9935 - val_loss: 1.1242 - val_acc: 0.7788\n",
            "Epoch 84/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0236 - acc: 0.9932 - val_loss: 1.1201 - val_acc: 0.7795\n",
            "Epoch 85/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0254 - acc: 0.9925 - val_loss: 1.1062 - val_acc: 0.7818\n",
            "Epoch 86/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0227 - acc: 0.9932 - val_loss: 1.1018 - val_acc: 0.7814\n",
            "Epoch 87/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0206 - acc: 0.9941 - val_loss: 1.1130 - val_acc: 0.7812\n",
            "Epoch 88/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0235 - acc: 0.9930 - val_loss: 1.1063 - val_acc: 0.7796\n",
            "Epoch 89/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0238 - acc: 0.9930 - val_loss: 1.1203 - val_acc: 0.7811\n",
            "Epoch 90/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0233 - acc: 0.9934 - val_loss: 1.1178 - val_acc: 0.7806\n",
            "Epoch 91/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0215 - acc: 0.9940 - val_loss: 1.1238 - val_acc: 0.7794\n",
            "Epoch 92/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0226 - acc: 0.9936 - val_loss: 1.1221 - val_acc: 0.7819\n",
            "Epoch 93/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0200 - acc: 0.9941 - val_loss: 1.1130 - val_acc: 0.7800\n",
            "Epoch 94/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0232 - acc: 0.9934 - val_loss: 1.1191 - val_acc: 0.7785\n",
            "Epoch 95/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0210 - acc: 0.9937 - val_loss: 1.1174 - val_acc: 0.7815\n",
            "Epoch 96/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0192 - acc: 0.9947 - val_loss: 1.1228 - val_acc: 0.7784\n",
            "Epoch 97/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0187 - acc: 0.9944 - val_loss: 1.1183 - val_acc: 0.7765\n",
            "Epoch 98/100\n",
            "390/390 [==============================] - 286s 734ms/step - loss: 0.0197 - acc: 0.9941 - val_loss: 1.1071 - val_acc: 0.7795\n",
            "Epoch 99/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0189 - acc: 0.9942 - val_loss: 1.1094 - val_acc: 0.7859\n",
            "Epoch 100/100\n",
            "390/390 [==============================] - 286s 733ms/step - loss: 0.0210 - acc: 0.9941 - val_loss: 1.1177 - val_acc: 0.7820\n",
            "10000/10000 [==============================] - 24s 2ms/step\n",
            "Test score: 1.1176799992084503\n",
            "Test accuracy: 0.782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7hu_2POOKpP",
        "colab_type": "code",
        "outputId": "afcf3dfa-99e3-4771-9873-8939e3849635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Oct 20 02:47:07 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ItaINMBD2wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}